{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import os\n",
    "sc = pyspark.SparkContext(appName=\"BigDataProject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dir = \"./BooksDataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://GiacomoPC:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>BigDataProject</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=BigDataProject>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Arthur Conan Doyle', 'Charles Dickens', 'Daniel Defoe', 'Edith Wharton', 'Jane Austen', 'Joseph Conrad', 'Lewis Carroll', 'Louisa May Alcott', 'Voltaire', 'William Shakespeare']\n"
     ]
    }
   ],
   "source": [
    "#Read Authors\n",
    "\n",
    "authors = []\n",
    "\n",
    "for file in os.listdir(my_dir):\n",
    "    d = os.path.join(my_dir, file)\n",
    "    if os.path.isdir(d):\n",
    "        res = file\n",
    "        authors.append(res)\n",
    "print(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Arthur Conan Doyle_Beyond the City.txt', 'Arthur Conan Doyle_The Adventure of the Cardboard Box.txt', 'Arthur Conan Doyle_The Adventure of the Dying Detective.txt', 'Arthur Conan Doyle_The Adventure of the Red Circle.txt', 'Arthur Conan Doyle_The Adventures of Gerard.txt', 'Arthur Conan Doyle_The Adventures of Sherlock Holmes.txt', 'Arthur Conan Doyle_The British Campaign in France and Flanders 1914.txt', \"Arthur Conan Doyle_The Cabman's Story.txt\", 'Arthur Conan Doyle_The Captain of the Polestar and Other Tales.txt', 'Arthur Conan Doyle_The case of Oscar Slater.txt'], ['Charles Dickens_A Christmas Carol.txt', 'Charles Dickens_American Notes for General Circulation.txt', 'Charles Dickens_Bardell v. Pickwick.txt', 'Charles Dickens_Bleak House.txt', \"Charles Dickens_Charles Dickens' Children Stories.txt\", 'Charles Dickens_David Copperfield.txt', 'Charles Dickens_Oliver Twist.txt', 'Charles Dickens_The Cricket on the Hearth.txt', 'Charles Dickens_The Life And Adventures Of Nicholas Nickleby.txt', 'Charles Dickens_The Mystery of Edwin Drood.txt'], ['Daniel Defoe_A Vindication of the Press.txt', 'Daniel Defoe_An American Robinson Crusoe.txt', 'Daniel Defoe_An Appeal to Honour and Justice, Though It Be of His Worst Enemies.txt', 'Daniel Defoe_And What if the Pretender should Come.txt', 'Daniel Defoe_Atalantis Major.txt', 'Daniel Defoe_Augusta Triumphans.txt', 'Daniel Defoe_History of the Plague in London.txt', 'Daniel Defoe_The Complete English Tradesman (1839 ed.).txt', 'Daniel Defoe_The Life and Adventures of Robinson Crusoe.txt', 'Daniel Defoe_The Storm. An Essay.txt'], ['Edith Wharton_Artemis to Actaeon, and Other Verses.txt', 'Edith Wharton_Bunner Sisters.txt', 'Edith Wharton_Coming Home.txt', 'Edith Wharton_Crucial Instances.txt', 'Edith Wharton_The Age of Innocence.txt', 'Edith Wharton_The Book of the Homeless.txt', 'Edith Wharton_The Choice.txt', 'Edith Wharton_The Custom of the Country.txt', 'Edith Wharton_The Decoration of Houses.txt', 'Edith Wharton_The Greater Inclination.txt'], ['Jane Austen_Emma.txt', 'Jane Austen_Lady Susan.txt', 'Jane Austen_Love and Freindship.txt', 'Jane Austen_Mansfield Park.txt', 'Jane Austen_Northanger Abbey.txt', 'Jane Austen_Persuasion.txt', 'Jane Austen_Pride and Prejudice.txt', 'Jane Austen_Sense and Sensibility.txt', 'Jane Austen_The Letters of Jane Austen.txt', 'Jane Austen_The Watsons.txt'], [\"Joseph Conrad_Almayer's Folly A Story of an Eastern River.txt\", 'Joseph Conrad_Amy Foster.txt', 'Joseph Conrad_Chance A Tale in Two Parts.txt', 'Joseph Conrad_End of the Tether.txt', 'Joseph Conrad_Falk.txt', 'Joseph Conrad_Gaspar Ruiz.txt', 'Joseph Conrad_Lord Jim.txt', 'Joseph Conrad_The Arrow of Gold.txt', 'Joseph Conrad_The Inheritors.txt', 'Joseph Conrad_The Mirror of the Sea.txt'], ['Lewis Carroll_A Tangled Tale.txt', \"Lewis Carroll_Alice's Adventures in Wonderland.txt\", 'Lewis Carroll_Eight or Nine Wise Words about Letter-Writing.txt', 'Lewis Carroll_Phantasmagoria.txt', 'Lewis Carroll_Rhyme and reason.txt', 'Lewis Carroll_Sylvie and Bruno.txt', 'Lewis Carroll_The Hunting of the Snark An Agony in Eight Fits.txt', 'Lewis Carroll_The Nursery Alice.txt', 'Lewis Carroll_Three Sunsets and Other Poems.txt', 'Lewis Carroll_Through the Looking-Glass.txt'], ['Louisa May Alcott_A Garland for Girls.txt', 'Louisa May Alcott_A Modern Cinderella; Or, The Little Old Shoe, and Other Stories.txt', 'Louisa May Alcott_Eight Cousins.txt', 'Louisa May Alcott_Flower Fables.txt', 'Louisa May Alcott_Hospital Sketches.txt', 'Louisa May Alcott_Jack and Jill.txt', \"Louisa May Alcott_Kitty's Class Day and Other Stories.txt\", 'Louisa May Alcott_Rose in Bloom.txt', 'Louisa May Alcott_The Candy Country.txt', 'Louisa May Alcott_Under the Lilacs.txt'], ['Voltaire_A Philosophical Dictionary, Volume 1 (of 10).txt', 'Voltaire_Candide.txt', 'Voltaire_International Short Stories, French.txt', 'Voltaire_Letters on England.txt', \"Voltaire_Library of the World's Best Mystery and Detective Stories.txt\", 'Voltaire_Micromegas.txt', 'Voltaire_Socrates.txt', \"Voltaire_The Fourth Book of Virgil's Aeneid and the Ninth Book of Voltaire's Henriad.txt\", 'Voltaire_The History of Peter the Great, Emperor of Russia.txt', 'Voltaire_Zadig; Or, The Book of Fate.txt'], ['William Shakespeare_Allâ€™s Well That Ends Well.txt', 'William Shakespeare_As You Like It.txt', 'William Shakespeare_Henry V.txt', 'William Shakespeare_Henry VIII.txt', 'William Shakespeare_The Comedie of Errors.txt', 'William Shakespeare_The Tragedie of Anthonie, and Cleopatra.txt', 'William Shakespeare_The Tragedie of Coriolanus.txt', 'William Shakespeare_The Tragedie of Cymbeline.txt', 'William Shakespeare_The Tragedie of Julius Caesar.txt', 'William Shakespeare_The Tragedy of Hamlet, Prince of Denmark.txt']]\n"
     ]
    }
   ],
   "source": [
    "#Read Books per Authors\n",
    "books = [[] for _ in range(len(authors))]\n",
    "\n",
    "\n",
    "for i in range(len(authors)):\n",
    "    mydiraut = my_dir+\"/\"+authors[i]\n",
    "    for file in os.listdir(mydiraut):\n",
    "        d = os.path.join(mydiraut, file)\n",
    "        books[i].append(file)\n",
    "\n",
    "print(books)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./BooksDataset\\Arthur Conan Doyle\\Arthur Conan Doyle_The case of Oscar Slater.txt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'RDD' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\giaco\\Desktop\\BigDataProject2023\\main.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/giaco/Desktop/BigDataProject2023/main.ipynb#W5sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m allWordsForAnAuthors \u001b[39m=\u001b[39m sc\u001b[39m.\u001b[39mparallelize(allWordsForAnAuthors)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/giaco/Desktop/BigDataProject2023/main.ipynb#W5sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m allWordsForAnAuthors\u001b[39m.\u001b[39mflatMap(\u001b[39mlambda\u001b[39;00m x : (x[\u001b[39m0\u001b[39m], x[\u001b[39m1\u001b[39m]))\u001b[39m.\u001b[39mreduceByKey(\u001b[39mlambda\u001b[39;00m v1, v2: v1\u001b[39m+\u001b[39mv2)\u001b[39m.\u001b[39msortByKey(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/giaco/Desktop/BigDataProject2023/main.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m sc\u001b[39m.\u001b[39;49mparallelize(allWordsForAnAuthors)\u001b[39m.\u001b[39msaveAsTextFile(\u001b[39m'\u001b[39m\u001b[39m./RDD/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGiacomo\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/giaco/Desktop/BigDataProject2023/main.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mauthors[i]\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mallWordsForAnAuthors\u001b[39m.\u001b[39mtake(\u001b[39m100\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/giaco/Desktop/BigDataProject2023/main.ipynb#W5sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m allWordsForAnAuthors \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\giaco\\anaconda3\\envs\\BigData\\lib\\site-packages\\pyspark\\context.py:564\u001b[0m, in \u001b[0;36mSparkContext.parallelize\u001b[1;34m(self, c, numSlices)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[39m# Make sure we distribute data evenly if it's smaller than self.batchSize\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m__len__\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mdir\u001b[39m(c):\n\u001b[1;32m--> 564\u001b[0m     c \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(c)    \u001b[39m# Make it a list so we can compute its length\u001b[39;00m\n\u001b[0;32m    565\u001b[0m batchSize \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mmin\u001b[39m(\u001b[39mlen\u001b[39m(c) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m numSlices, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batchSize \u001b[39mor\u001b[39;00m \u001b[39m1024\u001b[39m))\n\u001b[0;32m    566\u001b[0m serializer \u001b[39m=\u001b[39m BatchedSerializer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unbatched_serializer, batchSize)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'RDD' object is not iterable"
     ]
    }
   ],
   "source": [
    "def wordCount(file_path):\n",
    "    words = sc.textFile(file_path).filter(bool) \\\n",
    "                .flatMap(lambda line: line.split(\" \")) \\\n",
    "                .map(lambda w: w.lower()) \\\n",
    "                .map(lambda w: (w, 1)) \\\n",
    "                .reduceByKey(lambda v1, v2: v1 + v2) \\\n",
    "                .map(lambda x: (x[1], x[0])) \\\n",
    "                .sortByKey(False)\n",
    "    result = words.collect()\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "allWordsForAnAuthors = []\n",
    "\n",
    "for i in range(len(authors)):\n",
    "    for j in range(9,len(books[i])):\n",
    "        input_filename = os.path.join(my_dir, authors[i])\n",
    "        input_filename = os.path.join(input_filename, books[i][j])\n",
    "        print(input_filename)\n",
    "        wordsOfABook= wordCount(input_filename)\n",
    "        \n",
    "        allWordsForAnAuthors.append(wordsOfABook)\n",
    "\n",
    "\n",
    "    allWordsForAnAuthors = sc.parallelize(allWordsForAnAuthors)\n",
    "    allWordsForAnAuthors.flatMap(lambda x : (x[0], x[1])).reduceByKey(lambda v1, v2: v1+v2).sortByKey(False)\n",
    "    sc.parallelize(allWordsForAnAuthors).saveAsTextFile('./RDD/'+authors[i])\n",
    "\n",
    "    print(f\"{authors[i]} {allWordsForAnAuthors.take(100)}\")\n",
    "    allWordsForAnAuthors = []\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
